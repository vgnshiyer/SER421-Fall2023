---
title: "Learning Outcomes"
date: 2019-02-11T19:30:08+10:00
draft: false
weight: 1
summary: Upon completion of this learning module, participants will understand how to use Kafka for quick and effective handling of real-time data, helping them become skilled in data streaming by the end of the lesson.
---

### **By the end of this tutorial, you should be able to:**

---

1. **Understand the basic concepts and architecture of Apache Kafka:** Learn about Kafka's publish-subscribe model, its components (like producers, consumers, brokers, topics, partitions), and how data flows in Kafka.

2. **Install and set up Apache Kafka on your local machine:** Get hands-on experience installing Kafka and setting it up for development.

3. **Create Kafka Producers and Consumers in Java:** Write Java programs that produce messages to Kafka topics and consume messages from Kafka topics.

4. **Understand the structure and setup of a Kafka Cluster:** Learn about Kafka clusters, which consist of Kafka brokers, zookeeper for fault-tolerance, and how to set them up in docker.

5. **Apply best practices for running Kafka in a production environment:** Learn about considerations and best practices for running Kafka in a production environment, like monitoring, security, and tuning.

6. **Tune the performance of your Kafka setup:** Learn how to optimize Kafka's performance by tuning various parameters like batch size, linger time, and compression type.
