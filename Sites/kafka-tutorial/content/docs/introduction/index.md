---
title: 'Introduction'
date: 2019-02-11T19:30:08+10:00
draft: false
weight: 2
Summary: Apache Kafka, initially developed at LinkedIn and open-sourced in 2011, has a rich history as a distributed event streaming platform. Its founding principles prioritize scalability, fault tolerance, and low-latency processing, aiming to handle large-scale real-time data streams. Key features include a distributed architecture, publish-subscribe model, persistence, fault tolerance, and support for high-throughput data streaming. Adhering to standards like TCP and SASL, Kafka utilizes a binary protocol and ZooKeeper for coordination. Major releases, exemplified by Kafka 3.0 and 3.1, showcase continuous improvements, introducing features like the KRaft consensus mechanism and enhanced SASL/OAUTHBEARER, solidifying Kafka's status as a versatile and evolving platform for real-time data processing.
---

### **Brief History of Apache Kafka**
---
### **Founding Principles and Goals**
---
### **Key Features of Apache Kafka**
---
### **Standards and Protocols Used in Apache Kafka**
---
### **Major Releases and Improvements**
---